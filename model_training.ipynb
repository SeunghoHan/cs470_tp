{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "\n",
    "from data.load_datasets import *\n",
    "from models.decoder_with_attention import DecoderWithAttention\n",
    "import models.model_parameters as params\n",
    "from experiment._train_one_epoch import *\n",
    "from experiment._validation_one_epoch import *\n",
    "from experiment.utils import *\n",
    "from experiment.earlystopping import EarlyStopping\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read caption word map\n",
    "cap_word_map_file = os.path.join(params.data_folder, 'WORDMAP_' + params.data_name + '.json')\n",
    "with open(cap_word_map_file, 'r') as j:\n",
    "    cap_word_map = json.load(j)\n",
    "    \n",
    "# Read attribute word map\n",
    "attr_word_map_file = os.path.join(params.data_folder, 'ATTRS_WORDMAP_' + params.data_name + '.json')\n",
    "with open(attr_word_map_file, 'r') as j:\n",
    "    attr_word_map = json.load(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ckpt/BEST_checkpoint_6_preprocessed_coco.pth.tar\n",
      "Epoch: [6][0/11230]\tBatch Time 1.238 (1.238)\tData Load Time 0.361 (0.361)\tLoss 7.1797 (7.1797)\tTop-5 Accuracy 74.295 (74.295)\n",
      "Epoch: [6][100/11230]\tBatch Time 0.923 (0.942)\tData Load Time 0.348 (0.397)\tLoss 6.5271 (5.9042)\tTop-5 Accuracy 72.864 (75.700)\n",
      "Epoch: [6][200/11230]\tBatch Time 1.013 (0.936)\tData Load Time 0.396 (0.383)\tLoss 6.2957 (6.1198)\tTop-5 Accuracy 74.161 (75.340)\n",
      "Epoch: [6][300/11230]\tBatch Time 0.827 (0.936)\tData Load Time 0.364 (0.380)\tLoss 5.5104 (6.1418)\tTop-5 Accuracy 75.455 (75.381)\n",
      "Epoch: [6][400/11230]\tBatch Time 0.888 (0.937)\tData Load Time 0.402 (0.380)\tLoss 5.2416 (6.1726)\tTop-5 Accuracy 77.265 (75.379)\n",
      "Epoch: [6][500/11230]\tBatch Time 0.837 (0.936)\tData Load Time 0.354 (0.379)\tLoss 5.3971 (6.1861)\tTop-5 Accuracy 76.000 (75.349)\n",
      "Epoch: [6][600/11230]\tBatch Time 0.933 (0.936)\tData Load Time 0.407 (0.380)\tLoss 6.1418 (6.1827)\tTop-5 Accuracy 74.956 (75.383)\n",
      "Epoch: [6][700/11230]\tBatch Time 0.891 (0.936)\tData Load Time 0.409 (0.379)\tLoss 5.2732 (6.1898)\tTop-5 Accuracy 77.331 (75.352)\n",
      "Epoch: [6][800/11230]\tBatch Time 0.785 (0.936)\tData Load Time 0.342 (0.378)\tLoss 6.5848 (6.1839)\tTop-5 Accuracy 76.014 (75.335)\n",
      "Epoch: [6][900/11230]\tBatch Time 0.841 (0.933)\tData Load Time 0.334 (0.376)\tLoss 7.2506 (6.1741)\tTop-5 Accuracy 74.697 (75.358)\n",
      "Epoch: [6][1000/11230]\tBatch Time 1.378 (0.933)\tData Load Time 0.389 (0.374)\tLoss 5.5478 (6.1622)\tTop-5 Accuracy 75.333 (75.382)\n",
      "Epoch: [6][1100/11230]\tBatch Time 0.884 (0.931)\tData Load Time 0.307 (0.373)\tLoss 5.9910 (6.1732)\tTop-5 Accuracy 76.532 (75.383)\n",
      "Epoch: [6][1200/11230]\tBatch Time 0.930 (0.930)\tData Load Time 0.377 (0.372)\tLoss 6.1339 (6.1818)\tTop-5 Accuracy 76.962 (75.390)\n",
      "Epoch: [6][1300/11230]\tBatch Time 0.827 (0.928)\tData Load Time 0.316 (0.371)\tLoss 5.9332 (6.1863)\tTop-5 Accuracy 77.249 (75.384)\n",
      "Epoch: [6][1400/11230]\tBatch Time 0.863 (0.929)\tData Load Time 0.354 (0.370)\tLoss 6.2405 (6.2043)\tTop-5 Accuracy 75.559 (75.354)\n",
      "Epoch: [6][1500/11230]\tBatch Time 1.025 (0.930)\tData Load Time 0.537 (0.370)\tLoss 6.5374 (6.2107)\tTop-5 Accuracy 75.433 (75.352)\n",
      "Epoch: [6][1600/11230]\tBatch Time 0.936 (0.931)\tData Load Time 0.381 (0.370)\tLoss 5.5624 (6.2047)\tTop-5 Accuracy 80.920 (75.332)\n",
      "Epoch: [6][1700/11230]\tBatch Time 0.897 (0.931)\tData Load Time 0.382 (0.369)\tLoss 8.3729 (6.2118)\tTop-5 Accuracy 71.993 (75.307)\n",
      "Epoch: [6][1800/11230]\tBatch Time 0.826 (0.928)\tData Load Time 0.358 (0.368)\tLoss 5.4332 (6.2110)\tTop-5 Accuracy 78.731 (75.295)\n",
      "Epoch: [6][1900/11230]\tBatch Time 0.917 (0.927)\tData Load Time 0.385 (0.367)\tLoss 6.3935 (6.2029)\tTop-5 Accuracy 73.559 (75.320)\n",
      "Epoch: [6][2000/11230]\tBatch Time 0.944 (0.925)\tData Load Time 0.394 (0.365)\tLoss 6.5405 (6.2117)\tTop-5 Accuracy 72.872 (75.336)\n",
      "Epoch: [6][2100/11230]\tBatch Time 0.947 (0.923)\tData Load Time 0.463 (0.364)\tLoss 6.4369 (6.2017)\tTop-5 Accuracy 76.354 (75.345)\n",
      "Epoch: [6][2200/11230]\tBatch Time 0.855 (0.922)\tData Load Time 0.301 (0.363)\tLoss 6.4633 (6.2080)\tTop-5 Accuracy 73.729 (75.345)\n",
      "Epoch: [6][2300/11230]\tBatch Time 0.908 (0.920)\tData Load Time 0.419 (0.362)\tLoss 6.3482 (6.2112)\tTop-5 Accuracy 74.746 (75.332)\n",
      "Epoch: [6][2400/11230]\tBatch Time 0.850 (0.919)\tData Load Time 0.248 (0.361)\tLoss 5.5472 (6.2079)\tTop-5 Accuracy 78.188 (75.335)\n",
      "Epoch: [6][2500/11230]\tBatch Time 1.060 (0.919)\tData Load Time 0.315 (0.361)\tLoss 7.1324 (6.2107)\tTop-5 Accuracy 72.743 (75.319)\n",
      "Epoch: [6][2600/11230]\tBatch Time 0.841 (0.917)\tData Load Time 0.311 (0.361)\tLoss 5.1672 (6.2120)\tTop-5 Accuracy 78.383 (75.320)\n",
      "Epoch: [6][2700/11230]\tBatch Time 1.116 (0.917)\tData Load Time 0.347 (0.360)\tLoss 7.5876 (6.2135)\tTop-5 Accuracy 73.413 (75.315)\n",
      "Epoch: [6][2800/11230]\tBatch Time 0.927 (0.917)\tData Load Time 0.305 (0.360)\tLoss 4.7255 (6.2149)\tTop-5 Accuracy 78.246 (75.311)\n",
      "Epoch: [6][2900/11230]\tBatch Time 0.903 (0.916)\tData Load Time 0.325 (0.359)\tLoss 6.0081 (6.2130)\tTop-5 Accuracy 73.966 (75.314)\n",
      "Epoch: [6][3000/11230]\tBatch Time 0.968 (0.917)\tData Load Time 0.391 (0.361)\tLoss 4.4032 (6.2107)\tTop-5 Accuracy 75.795 (75.310)\n",
      "Epoch: [6][3100/11230]\tBatch Time 1.005 (0.917)\tData Load Time 0.366 (0.360)\tLoss 6.2606 (6.2044)\tTop-5 Accuracy 75.465 (75.324)\n",
      "Epoch: [6][3200/11230]\tBatch Time 0.798 (0.919)\tData Load Time 0.353 (0.362)\tLoss 5.1681 (6.2015)\tTop-5 Accuracy 76.820 (75.322)\n",
      "Epoch: [6][3300/11230]\tBatch Time 1.009 (0.920)\tData Load Time 0.431 (0.363)\tLoss 6.6530 (6.1962)\tTop-5 Accuracy 74.868 (75.328)\n",
      "Epoch: [6][3400/11230]\tBatch Time 0.854 (0.921)\tData Load Time 0.342 (0.364)\tLoss 5.2024 (6.1913)\tTop-5 Accuracy 76.655 (75.330)\n",
      "Epoch: [6][3500/11230]\tBatch Time 0.777 (0.922)\tData Load Time 0.244 (0.364)\tLoss 7.2149 (6.1965)\tTop-5 Accuracy 73.345 (75.310)\n",
      "Epoch: [6][3600/11230]\tBatch Time 1.010 (0.921)\tData Load Time 0.450 (0.364)\tLoss 7.0470 (6.1980)\tTop-5 Accuracy 75.248 (75.302)\n",
      "Epoch: [6][3700/11230]\tBatch Time 0.906 (0.922)\tData Load Time 0.329 (0.364)\tLoss 6.9942 (6.1994)\tTop-5 Accuracy 76.379 (75.296)\n",
      "Epoch: [6][3800/11230]\tBatch Time 0.884 (0.922)\tData Load Time 0.358 (0.364)\tLoss 6.7024 (6.2011)\tTop-5 Accuracy 74.464 (75.286)\n",
      "Epoch: [6][3900/11230]\tBatch Time 0.767 (0.921)\tData Load Time 0.283 (0.364)\tLoss 5.9960 (6.2011)\tTop-5 Accuracy 74.545 (75.284)\n",
      "Epoch: [6][4000/11230]\tBatch Time 0.829 (0.921)\tData Load Time 0.314 (0.363)\tLoss 5.7340 (6.2004)\tTop-5 Accuracy 72.391 (75.282)\n",
      "Epoch: [6][4100/11230]\tBatch Time 1.057 (0.924)\tData Load Time 0.395 (0.367)\tLoss 4.9510 (6.2000)\tTop-5 Accuracy 75.298 (75.275)\n"
     ]
    }
   ],
   "source": [
    "# Custom dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(params.data_folder, params.data_name, 'TRAIN'),\n",
    "    batch_size=params.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=params.workers, \n",
    "    pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(params.data_folder, params.data_name, 'VAL'),\n",
    "    batch_size=params.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=params.workers, \n",
    "    pin_memory=True)\n",
    "\n",
    "checkpoint = os.path.join(params.ckpt_folder, params.checkpoint)\n",
    "# Initialize / load checkpoint\n",
    "if checkpoint is None: \n",
    "    # Creaste new visual-semantic attention decoder\n",
    "    start_epoch = 0\n",
    "    vs_att_decoder = DecoderWithAttention(visual_attention_dim=params.visual_attention_dim,\n",
    "                                          semantic_attention_dim=params.semantic_attention_dim,\n",
    "                                          cap_embed_dim=params.cap_emb_dim,\n",
    "                                          attr_embed_dim=params.attr_emb_dim,\n",
    "                                          decoder_dim=params.decoder_dim,\n",
    "                                          cap_vocab_size=len(cap_word_map),\n",
    "                                          attr_vocab_size=len(attr_word_map),\n",
    "                                          features_dim=params.features_dim,\n",
    "                                          dropout=params.dropout_rate)\n",
    "    decoder_optimizer = torch.optim.Adamax(params=filter(lambda p: p.requires_grad, vs_att_decoder.parameters()))\n",
    "\n",
    "else:\n",
    "    print(\"Loading checkpoint: {}\".format(checkpoint))\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
    "    best_bleu4 = checkpoint['bleu-4']\n",
    "    vs_att_decoder = checkpoint['decoder']\n",
    "    decoder_optimizer = checkpoint['decoder_optimizer']\n",
    "    \n",
    "    \n",
    "# Move to GPU, if available\n",
    "vs_att_decoder = vs_att_decoder.to(params.device)\n",
    "\n",
    "# Loss functions\n",
    "loss_fn_ce = nn.CrossEntropyLoss().to(params.device)\n",
    "loss_fn_dis = nn.MultiLabelMarginLoss().to(params.device)\n",
    "\n",
    "# For EarlyStopping & Decaying learning rate\n",
    "best_bleu4 = 0.  # BLEU-4 score right now\n",
    "earlystop = EarlyStopping(best_bleu4, params.max_patience)\n",
    "\n",
    "for epoch in range(start_epoch, params.epochs):\n",
    "    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "    if earlystop.patience > 0 and earlystop.patience % params.decay_epochs_interval == 0:\n",
    "        earlystop.lr_decay(optimizer, 0.8)\n",
    "        \n",
    "    if earlystop.patience == earlystop.max_patience: break\n",
    "    \n",
    "    # One epoch's training\n",
    "    train(train_loader=train_loader,\n",
    "          vs_att_decoder=vs_att_decoder,\n",
    "          loss_fn_ce=loss_fn_ce,\n",
    "          loss_fn_dis=loss_fn_dis,\n",
    "          decoder_optimizer=decoder_optimizer,\n",
    "          epoch=epoch)\n",
    "\n",
    "\n",
    "    # One epoch's validation\n",
    "    recent_bleu4 = validate(val_loader=val_loader,\n",
    "                            vs_att_decoder=vs_att_decoder,\n",
    "                            loss_fn_ce=loss_fn_ce,\n",
    "                            loss_fn_dis=loss_fn_dis,\n",
    "                            word_map=cap_word_map)\n",
    "    \n",
    "    # Check if there was an improvement\n",
    "    is_improved = earlystop.check_improvement(recent_bleu4)\n",
    "    \n",
    "    state_dict = {'epoch': epoch,\n",
    "                  'epochs_since_improvement': earlystop.patience,\n",
    "                  'bleu-4': recent_bleu4,\n",
    "                  'decoder': vs_att_decoder,\n",
    "                  'decoder_optimizer': decoder_optimizer}\n",
    "    \n",
    "    ckpt_path = os.path.join(params.ckpt_folder, \n",
    "                             'checkpoint_' + str(epoch+1) + '_' + params.data_name + '.pth.tar')\n",
    "    torch.save(state_dict, ckpt_path)\n",
    "    if is_improved:\n",
    "        ckpt_path = os.path.join(params.ckpt_folder, \n",
    "                                 'BEST_checkpoint_' + str(epoch+1) + '_' + params.data_name + '.pth.tar')\n",
    "        torch.save(state_dict, ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
